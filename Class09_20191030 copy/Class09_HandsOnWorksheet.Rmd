---
title: "Class 09-HandsOnWorksheet"
author: "Analine Aguayo"
date: "10/30/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
wisc.df <- read.csv("WisconsinCancer.csv")
head(wisc.df)
wisc.df

```

Here we examine the data from `r nrow(wisc.df)` patient samples.
```{r}
nrow(wisc.df)
ncol(wisc.df)
```

```{r}
table(wisc.df$diagnosis)
x <- table(wisc.df$diagnosis)
x
```
I this data-set we have `r x["M"]` cancer and `r x["B"]` non-cancer.

```{r}
# Convert the features of the data: wisc.data
wisc.data <- as.matrix(wisc.df[,3:32])
wisc.data
```

```{r}
colnames(wisc.df)
```

```{r}
help("grep")
```
```{r}
grep("_mean", colnames(wisc.df), value = TRUE)
```
grep allows you to look for patterns. value argument will either tell you the names of the positives or not. 
```{r}
grep("_mean", colnames(wisc.df), value = TRUE)
length(grep("_mean", colnames(wisc.df), value = TRUE))
```

```{r}
colMeans(wisc.data)
```

# Check column means and standard deviations
colMeans(wisc.data)

apply(wisc.data,2,sd)

##Principal ComponentAnalaysis
The next step in our analysis is to perform principal componennt analysis (PCA) on wisc.data

```{r}
round(apply(wisc.data,2,sd), 3)
```

Ë†Loosks like we need to use `scale-=TRUE` here as our data are all over the shop...
```{r}
##Perform PCA on wisc.data by completing the following code
wisc.pr <- prcomp( wisc.data, scale = TRUE)
summary(wisc.pr)

#we had to scale because the sd of all of the data were very different. Some had under one and some had values of over 400.
```

```{r}
plot(wisc.pr$x)
```

```{r}
plot(wisc.pr$rotation)
```

Plot PC1 vs PC2 and color by M/B cancer/non-cancer diagnosis
```{r}
plot(wisc.pr$x, col= ,
    xlab = "PC1", ylab = "PC2")


```

```{r}
#without color
plot(wisc.pr$x[,1], wisc.pr$x[,2])
```

```{r}
#with color
plot(wisc.pr$x[,1:2], col=wisc.df$diagnosis)
```

```{r}
x <- summary(wisc.pr)
x
x$importance
```
```{r}
x$importance[,"PC1"]
```

#The first PC satures `r x$importance[2, "PC1" *100' of the original variance of the data set.

```{r}
x$importance[3,] > 0.7
```
> Q How many principal components are required to describe at least 70% of the original variance in the data?

```{r}
which(x$importance[3,] > 0.7)[1]
```

```{r}
hclust(dist(wisc.pr$x[1:3]))
```
```{r}
## Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
hclust(dist(wisc.pr$x[,1:3]))
y <- hclust(dist(wisc.pr$x[,1:3]))
plot(y)

```
```{r}
grps <- cutree(y, k=2)
table(grps)
```



```{r}
hclust(dist(wisc.pr$x[,1:3]))
z <- hclust(dist(wisc.pr$x[,1:7]))
plot(z)
```


```{r}

data.scaled <- scale(wisc.data)
wisc.hclust <-hclust(dist(data.scaled))
plot(wisc.hclust)

```

this looks quite awful!

Lets now try clustering in PCA space

We will take the results of `prcomp()` and build our distance matrix in PC space rather than from our raw data.

```{r}
#take first 7 PCs
wisc.pr.hclust <- hclust (dist(wisc.pr$x[, 1:7]), method="ward.D2")
plot(wisc.pr.hclust)
```

and the cluster membership vector can be obtained `cutree()`

```{r}
grps <- cutree(wisc.pr.hclust, h=70)
table(grps)
```

```{r}
table(wisc.df$diagnosis)
```
```{r}
table(grps, wisc.df$diagnosis)
```

lets compare i.e. cross tabulate these results:
table(grps, wisc.df$diagnosis)
```{r}
plot(wisc.pr$x[,1:2], col=wisc.df$diagnosis)
points(npc[,1],npc[,2],col="blue",pch=15, cex=3)
text(npc[,1], npc[,2], labels = c(1,2), col="white")
```



We will be using a new function predict
```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
points(npc[,1], npc[,2], col="blue", pch=16)


```

see above graph with big blue dots and white numbers.